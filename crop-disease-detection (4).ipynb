{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":150545,"sourceType":"datasetVersion","datasetId":70909}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, random_split\nimport torchvision.transforms as transforms\nfrom torchvision import datasets, transforms\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import precision_recall_curve, average_precision_score\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.metrics import classification_report, precision_recall_curve, average_precision_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T09:50:04.222440Z","iopub.status.idle":"2025-08-17T09:50:04.222655Z","shell.execute_reply.started":"2025-08-17T09:50:04.222554Z","shell.execute_reply":"2025-08-17T09:50:04.222563Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n\ndata_dir = \"/kaggle/input/plantdisease/PlantVillage\"\n\n\nprint(os.path.exists(data_dir))  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T09:50:04.223698Z","iopub.status.idle":"2025-08-17T09:50:04.223935Z","shell.execute_reply.started":"2025-08-17T09:50:04.223835Z","shell.execute_reply":"2025-08-17T09:50:04.223844Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntransform = transforms.Compose([\n    transforms.Resize((256, 256)),                 \n    transforms.RandomResizedCrop(224),              \n    transforms.RandomHorizontalFlip(p=0.5),          \n    transforms.RandomRotation(degrees=15),           \n    transforms.ColorJitter(brightness=0.2,          \n                           contrast=0.2, \n                           saturation=0.2, \n                           hue=0.1), \n    transforms.ToTensor(),                           \n    transforms.Normalize(mean=[0.485, 0.456, 0.406], # standard ImageNet normalization\n                         std=[0.229, 0.224, 0.225])\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T09:50:04.224914Z","iopub.status.idle":"2025-08-17T09:50:04.225606Z","shell.execute_reply.started":"2025-08-17T09:50:04.225430Z","shell.execute_reply":"2025-08-17T09:50:04.225447Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndataset = datasets.ImageFolder(root=data_dir, transform=transform)\n\n# Sizes\ntrain_size = int(0.7 * len(dataset))  \nval_size = int(0.1 * len(dataset))     \ntest_size = len(dataset) - train_size - val_size  \n\n# Split\ntrain_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n\n# Loaders\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) #batch size=a rule of thumb in research","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T09:50:04.226288Z","iopub.status.idle":"2025-08-17T09:50:04.226522Z","shell.execute_reply.started":"2025-08-17T09:50:04.226406Z","shell.execute_reply":"2025-08-17T09:50:04.226419Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\nclass SimpleCNN(nn.Module):\n    def __init__(self, num_classes):\n        super(SimpleCNN, self).__init__()\n        \n        \n        self.conv1_weight = nn.Parameter(torch.randn(16, 3, 3, 3) * 0.01)\n        self.conv1_bias   = nn.Parameter(torch.zeros(16))\n        self.conv2_weight = nn.Parameter(torch.randn(32, 16, 3, 3) * 0.01)\n        self.conv2_bias   = nn.Parameter(torch.zeros(32))\n        self.conv3_weight = nn.Parameter(torch.randn(64, 32, 3, 3) * 0.01)\n        self.conv3_bias   = nn.Parameter(torch.zeros(64))\n        \n     \n        self.fc1_weight = nn.Parameter(torch.randn(128, 64 * 28 * 28) * 0.01)\n        self.fc1_bias   = nn.Parameter(torch.zeros(128))\n        self.fc2_weight = nn.Parameter(torch.randn(num_classes, 128) * 0.01)\n        self.fc2_bias   = nn.Parameter(torch.zeros(num_classes))\n        \n       \n        self.dropout_p = 0.5\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T09:50:04.227540Z","iopub.status.idle":"2025-08-17T09:50:04.227766Z","shell.execute_reply.started":"2025-08-17T09:50:04.227669Z","shell.execute_reply":"2025-08-17T09:50:04.227678Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn.functional as F\n\ndef forward(self, x):\n   \n    x = F.conv2d(x, self.conv1_weight, self.conv1_bias, stride=1, padding=1) \n    x = F.leaky_relu(x, negative_slope=0.01)  #to avoid dead  cell\n    x = F.max_pool2d(x, 2, 2)\n    \n   \n    x = F.conv2d(x, self.conv2_weight, self.conv2_bias, stride=1, padding=1)\n    x = F.leaky_relu(x, negative_slope=0.01)  \n    x = F.max_pool2d(x, 2, 2) #reduce 50% dimension\n    \n   \n    x = F.conv2d(x, self.conv3_weight, self.conv3_bias, stride=1, padding=1)\n    x = F.leaky_relu(x, negative_slope=0.01)   \n    x = F.max_pool2d(x, 2, 2)\n    \n    \n    x = x.view(-1, 64 * 28 * 28)\n    \n  \n    x = F.linear(x, self.fc1_weight, self.fc1_bias)\n    x = F.leaky_relu(x, negative_slope=0.01)  \n    x = F.dropout(x, p=self.dropout_p, training=self.training)\n    \n    \n    x = F.linear(x, self.fc2_weight, self.fc2_bias)\n    return x\n\n\nSimpleCNN.forward = forward\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T09:50:04.228878Z","iopub.status.idle":"2025-08-17T09:50:04.229212Z","shell.execute_reply.started":"2025-08-17T09:50:04.229055Z","shell.execute_reply":"2025-08-17T09:50:04.229071Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_classes = len(dataset.classes)  # Number of disease categories\nmodel = SimpleCNN(num_classes)\nprint(model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T09:50:04.229964Z","iopub.status.idle":"2025-08-17T09:50:04.230215Z","shell.execute_reply.started":"2025-08-17T09:50:04.230097Z","shell.execute_reply":"2025-08-17T09:50:04.230107Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\nimport torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()       \noptimizer = optim.Adam(model.parameters(), lr=0.001)  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T09:50:04.231024Z","iopub.status.idle":"2025-08-17T09:50:04.231358Z","shell.execute_reply.started":"2025-08-17T09:50:04.231185Z","shell.execute_reply":"2025-08-17T09:50:04.231202Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lr = 0.001\nnum_epochs = 12\nmax_norm = 1.0\n\n# Use standard PyTorch loss & optimizer\ncriterion = nn.CrossEntropyLoss()  # Combines softmax + log loss\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\nfor epoch in range(num_epochs):\n    running_loss = 0.0\n    model.train()\n    \n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        \n        # --- Forward pass ---\n        outputs = model(images)\n        loss = criterion(outputs, labels)  # directly use labels\n        \n        # --- Backward pass ---\n        optimizer.zero_grad()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n        optimizer.step()\n        \n        running_loss += loss.item()\n    \n    train_loss = running_loss / len(train_loader)\n    \n    # --- Validation loop ---\n    model.eval()\n    val_running_loss = 0.0\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            val_loss = criterion(outputs, labels)\n            val_running_loss += val_loss.item()\n    \n    val_loss = val_running_loss / len(val_loader)\n    \n    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n          f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T09:50:04.232126Z","iopub.status.idle":"2025-08-17T09:50:04.232388Z","shell.execute_reply.started":"2025-08-17T09:50:04.232277Z","shell.execute_reply":"2025-08-17T09:50:04.232289Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()  \ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():  \n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f\"Test Accuracy: {100 * correct / total:.2f}%\") #rafi\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T09:50:04.233531Z","iopub.status.idle":"2025-08-17T09:50:04.233856Z","shell.execute_reply.started":"2025-08-17T09:50:04.233686Z","shell.execute_reply":"2025-08-17T09:50:04.233700Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n\nimage_index = 111\nimage, label = test_dataset[image_index]\n\n\nplt.imshow(image.permute(1, 2, 0))  \nplt.title(f\"Actual: {dataset.classes[label]}\")\nplt.axis('on')\nplt.show()\n\n\nimage = image.unsqueeze(0).to(device)  \n\n\nmodel.eval()\nwith torch.no_grad():\n    output = model(image)\n    _, predicted = torch.max(output, 1)#to ignore max value need max index\n\npredicted_class = dataset.classes[predicted.item()]\nprint(f\"Predicted: {predicted_class}\")\nprint(len(dataset))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T09:50:04.234921Z","iopub.status.idle":"2025-08-17T09:50:04.235197Z","shell.execute_reply.started":"2025-08-17T09:50:04.235027Z","shell.execute_reply":"2025-08-17T09:50:04.235066Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\nmodel.eval()\ny_true = []\ny_pred = []\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        outputs = model(images)\n        probs = F.softmax(outputs, dim=1)\n        preds = torch.argmax(probs, dim=1) \n\n        y_true.extend(labels.cpu().numpy())\n        y_pred.extend(preds.cpu().numpy())\n\n\ny_true = np.array(y_true)\ny_pred = np.array(y_pred)\n\n\ncm = confusion_matrix(y_true, y_pred)\n\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot(cmap=plt.cm.Reds, xticks_rotation=180)\nplt.title(\"Confusion Matrix - Crop Disease Detection\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T09:50:04.236363Z","iopub.status.idle":"2025-08-17T09:50:04.236573Z","shell.execute_reply.started":"2025-08-17T09:50:04.236477Z","shell.execute_reply":"2025-08-17T09:50:04.236486Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n\nmodel.eval()\n\ny_true = []\ny_scores = []\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        outputs = model(images) \n        probs = F.softmax(outputs, dim=1) \n\n        y_true.extend(labels.cpu().numpy())\n        y_scores.extend(probs.cpu().numpy())\n\ny_true = np.array(y_true)\ny_scores = np.array(y_scores)\n\n\ny_pred = np.argmax(y_scores, axis=1)\nreport = classification_report(y_true, y_pred, target_names=dataset.classes)\nprint(\"Classification Report (Precision, Recall, F1-score per class):\\n\")\nprint(report)\n\nn_classes = y_scores.shape[1]\nplt.figure(figsize=(12, 8))\n\nfor i in range(n_classes):\n    precision, recall, thresholds = precision_recall_curve(y_true == i, y_scores[:, i])\n    ap = average_precision_score(y_true == i, y_scores[:, i])\n    plt.plot(recall, precision, label=f'{dataset.classes[i]} (AP={ap:.2f})')\n\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Precision-Recall Tradeoff per Class\")\nplt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')  \nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T09:50:04.237332Z","iopub.status.idle":"2025-08-17T09:50:04.237559Z","shell.execute_reply.started":"2025-08-17T09:50:04.237456Z","shell.execute_reply":"2025-08-17T09:50:04.237466Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}