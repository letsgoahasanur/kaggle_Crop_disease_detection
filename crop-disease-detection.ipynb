{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":150545,"sourceType":"datasetVersion","datasetId":70909}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\n# Set dataset path\ndata_dir = \"/kaggle/input/plantdisease/PlantVillage\"\n\n# Optional: check if the path exists\nprint(os.path.exists(data_dir))  # Should print True\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T08:04:25.180731Z","iopub.execute_input":"2025-08-15T08:04:25.181129Z","iopub.status.idle":"2025-08-15T08:04:25.192546Z","shell.execute_reply.started":"2025-08-15T08:04:25.181097Z","shell.execute_reply":"2025-08-15T08:04:25.191852Z"}},"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import datasets, transforms\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T08:04:28.412105Z","iopub.execute_input":"2025-08-15T08:04:28.412362Z","iopub.status.idle":"2025-08-15T08:04:35.500749Z","shell.execute_reply.started":"2025-08-15T08:04:28.412342Z","shell.execute_reply":"2025-08-15T08:04:35.500205Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),#tensor is like a multi-dimensional array (matrix) that PyTorch can do math on.\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T08:04:38.113983Z","iopub.execute_input":"2025-08-15T08:04:38.114602Z","iopub.status.idle":"2025-08-15T08:04:38.118593Z","shell.execute_reply.started":"2025-08-15T08:04:38.114578Z","shell.execute_reply":"2025-08-15T08:04:38.117940Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n\ntrain_size = int(0.8 * len(dataset))\ntest_size = len(dataset) - train_size\ntrain_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T08:04:42.840107Z","iopub.execute_input":"2025-08-15T08:04:42.840651Z","iopub.status.idle":"2025-08-15T08:05:47.054347Z","shell.execute_reply.started":"2025-08-15T08:04:42.840627Z","shell.execute_reply":"2025-08-15T08:05:47.053781Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\n# Define a simple CNN\nclass SimpleCNN(nn.Module):\n    def __init__(self, num_classes):\n        super(SimpleCNN, self).__init__()\n        # 1st convolutional layer\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)  # Max pooling\n        # 2nd convolutional layer\n        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n        # Fully connected layers\n        self.fc1 = nn.Linear(32 * 56 * 56, 128)  # 224->112 after pool->56\n        self.fc2 = nn.Linear(128, num_classes)\n\n    def forward(self, x):#self allows you to access all the layers and attributes\n        x = self.pool(F.relu(self.conv1(x)))  # Conv1 -> ReLU -> Pool\n        x = self.pool(F.relu(self.conv2(x)))  # Conv2 -> ReLU -> Pool\n        x = x.view(-1, 32 * 56 * 56)          # Flatten\n        x = F.relu(self.fc1(x))               # FC1 -> ReLU\n        x = self.fc2(x)                       # FC2 -> output\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T08:07:00.881968Z","iopub.execute_input":"2025-08-15T08:07:00.882248Z","iopub.status.idle":"2025-08-15T08:07:00.888243Z","shell.execute_reply.started":"2025-08-15T08:07:00.882225Z","shell.execute_reply":"2025-08-15T08:07:00.887411Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"num_classes = len(dataset.classes)  # Number of disease categories\nmodel = SimpleCNN(num_classes)\nprint(model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T08:07:05.074448Z","iopub.execute_input":"2025-08-15T08:07:05.074706Z","iopub.status.idle":"2025-08-15T08:07:05.189485Z","shell.execute_reply.started":"2025-08-15T08:07:05.074685Z","shell.execute_reply":"2025-08-15T08:07:05.188903Z"}},"outputs":[{"name":"stdout","text":"SimpleCNN(\n  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (fc1): Linear(in_features=100352, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=15, bias=True)\n)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\nimport torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()       # Loss function for classification\noptimizer = optim.Adam(model.parameters(), lr=0.001)  # Optimizer\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T08:07:15.809317Z","iopub.execute_input":"2025-08-15T08:07:15.809586Z","iopub.status.idle":"2025-08-15T08:07:16.092633Z","shell.execute_reply.started":"2025-08-15T08:07:15.809564Z","shell.execute_reply":"2025-08-15T08:07:16.092065Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"num_epochs = 5  # You can increase later if needed\n\nfor epoch in range(num_epochs):\n    running_loss = 0.0\n    model.train()  # Set model to training mode\n\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()           # Reset gradients\n        outputs = model(images)         # Forward pass\n        loss = criterion(outputs, labels)  # Calculate loss\n        loss.backward()                 # Backpropagation\n        optimizer.step()                # Update weights\n\n        running_loss += loss.item()\n\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T08:07:22.675584Z","iopub.execute_input":"2025-08-15T08:07:22.676205Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/5], Loss: 1.0409\nEpoch [2/5], Loss: 0.3562\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"model.eval()  # Set model to evaluation mode\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():  # No gradient needed for evaluation\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}